#! /usr/bin/env python
#  -*- coding: utf-8 -*-
#
# GUI module generated by PAGE version 6.0.1
#  in conjunction with Tcl version 8.6
#    Dec 20, 2020 02:38:17 AM PKT  platform: Windows NT

import sys,uuid,os,requests,json,urllib,time,uuid
from tkinter import *  
from concurrent.futures import ThreadPoolExecutor 
from bs4 import BeautifulSoup as bs4
import tkinter as tk
from iteration_utilities import unique_everseen 
from tkinter import filedialog
from tkinter import *

# try:
#     import Tkinter as tk
# except ImportError:


# try:
#     import ttk
#     py3 = False
# except ImportError:
#     import tkinter.ttk as ttk
#     py3 = True
import ctypes

myappid = 'mycompany.myproduct.subproduct.1.0' 
ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(myappid)

import unknown_support

def vp_start_gui():
    '''Starting point when module is the main routine.'''
    global val, w, root
    root = tk.Tk()
    root.iconbitmap('ico.ico') 
    top = Toplevel1 (root)
    unknown_support.init(root, top)
    root.mainloop()

w = None
def create_Toplevel1(rt, *args, **kwargs):
    '''Starting point when module is imported by another module.
       Correct form of call: 'create_Toplevel1(root, *args, **kwargs)' .'''
    global w, w_win, root
    #rt = root
    root = rt
    w = tk.Toplevel (root)
    top = Toplevel1 (w)
    unknown_support.init(w, top, *args, **kwargs)
    return (w, top)

def destroy_Toplevel1():
    global w
    w.destroy()
    w = None

class Toplevel1:
     def __init__(self, top=None):
        self.f1pinfo={}
        self.f2pinfo={}
        self.sessionused=[]
        self.CRAWLINGCOMPLETED=True
        self.inputfolderlocation=''
        self.inputtargeturl=''
        self.inputprojectname=''
        self.OSGETCWD=''
        
        '''This class configures and populates the toplevel window.
           top is the toplevel containing window.'''
        _bgcolor = '#d9d9d9'  # X11 color: 'gray85'
        _fgcolor = '#000000'  # X11 color: 'black'
        _compcolor = '#d9d9d9' # X11 color: 'gray85'
        _ana1color = '#d9d9d9' # X11 color: 'gray85'
        _ana2color = '#ececec' # Closest X11 color: 'gray92'

        top.geometry("930x661+-1167+77")
        top.minsize(930, 661)
        top.maxsize(930, 661)
        top.resizable(1,  1)
        top.title("Web Crawler")
        top.configure(background="#d9d9d9")
        top.configure(highlightbackground="#d9d9d9")
        top.configure(highlightcolor="black")

        self.setupwindow = tk.LabelFrame(top)
        self.setupwindow.place(relx=0.011, rely=0.015, relheight=0.976
                , relwidth=0.985)
        self.setupwindow.configure(relief='groove')
        self.setupwindow.configure(foreground="black")
        self.setupwindow.configure(text='''Project Setup''')
        self.setupwindow.configure(background="#d9d9d9")
        self.setupwindow.configure(highlightbackground="#d9d9d9")
        self.setupwindow.configure(highlightcolor="black")

        self.Labelframe1_1 = tk.LabelFrame(self.setupwindow)
        self.Labelframe1_1.place(relx=0.011, rely=0.047, relheight=0.152
                , relwidth=0.979, bordermode='ignore')
        self.Labelframe1_1.configure(relief='groove')
        self.Labelframe1_1.configure(foreground="black")
        self.Labelframe1_1.configure(text='''Folder Location''')
        self.Labelframe1_1.configure(background="#d9d9d9")
        self.Labelframe1_1.configure(highlightbackground="#d9d9d9")
        self.Labelframe1_1.configure(highlightcolor="black")

        self.folderlocation_1 = tk.Entry(self.Labelframe1_1)
        self.folderlocation_1.place(relx=0.01, rely=0.327, height=40
                , relwidth=0.818, bordermode='ignore')
        self.folderlocation_1.configure(background="white")
        self.folderlocation_1.configure(disabledforeground="#a3a3a3")
        self.folderlocation_1.configure(font="-family {Microsoft PhagsPa} -size 13")
        self.folderlocation_1.configure(foreground="#000000")
        self.folderlocation_1.configure(highlightbackground="#d9d9d9")
        self.folderlocation_1.configure(highlightcolor="black")
        self.folderlocation_1.configure(insertbackground="black")
        self.folderlocation_1.configure(selectbackground="blue")
        self.folderlocation_1.configure(selectforeground="white")
        self.folderlocation_1.configure(state='readonly')

        self.browse_1 = tk.Button(self.Labelframe1_1)
        self.browse_1.place(relx=0.848, rely=0.306, height=39, width=127
                , bordermode='ignore')
        self.browse_1.configure(activebackground="#ececec")
        self.browse_1.configure(activeforeground="#000000")
        self.browse_1.configure(background="#d9d9d9")
        self.browse_1.configure(command=self.openfolder)
        self.browse_1.configure(cursor="hand2")
        self.browse_1.configure(disabledforeground="#a3a3a3")
        self.browse_1.configure(font="-family {Microsoft PhagsPa} -size 13")
        self.browse_1.configure(foreground="#000000")
        self.browse_1.configure(highlightbackground="#d9d9d9")
        self.browse_1.configure(highlightcolor="black")
        self.browse_1.configure(pady="0")
        self.browse_1.configure(text='''Browse''')

        self.Labelframe2_2 = tk.LabelFrame(self.setupwindow)
        self.Labelframe2_2.place(relx=0.011, rely=0.214, relheight=0.166
                , relwidth=0.981, bordermode='ignore')
        self.Labelframe2_2.configure(relief='groove')
        self.Labelframe2_2.configure(foreground="black")
        self.Labelframe2_2.configure(text='''Target URL''')
        self.Labelframe2_2.configure(background="#d9d9d9")
        self.Labelframe2_2.configure(highlightbackground="#d9d9d9")
        self.Labelframe2_2.configure(highlightcolor="black")

        self.targeturl_2 = tk.Entry(self.Labelframe2_2)
        self.targeturl_2.place(relx=0.011, rely=0.336, height=40, relwidth=0.972
                , bordermode='ignore')
        self.targeturl_2.configure(background="white")
        self.targeturl_2.configure(disabledforeground="#a3a3a3")
        self.targeturl_2.configure(font="-family {Microsoft PhagsPa} -size 13")
        self.targeturl_2.configure(foreground="#000000")
        self.targeturl_2.configure(highlightbackground="#d9d9d9")
        self.targeturl_2.configure(highlightcolor="black")
        self.targeturl_2.configure(insertbackground="black")
        self.targeturl_2.configure(selectbackground="blue")
        self.targeturl_2.configure(selectforeground="white")

        self.Labelframe3_1 = tk.LabelFrame(self.setupwindow)
        self.Labelframe3_1.place(relx=0.011, rely=0.397, relheight=0.166
                , relwidth=0.981, bordermode='ignore')
        self.Labelframe3_1.configure(relief='groove')
        self.Labelframe3_1.configure(foreground="black")
        self.Labelframe3_1.configure(text='''Project Name''')
        self.Labelframe3_1.configure(background="#d9d9d9")
        self.Labelframe3_1.configure(highlightbackground="#d9d9d9")
        self.Labelframe3_1.configure(highlightcolor="black")

        self.projectname_1 = tk.Entry(self.Labelframe3_1)
        self.projectname_1.place(relx=0.011, rely=0.318, height=40
                , relwidth=0.972, bordermode='ignore')
        self.projectname_1.configure(background="white")
        self.projectname_1.configure(disabledforeground="#a3a3a3")
        self.projectname_1.configure(font="-family {Microsoft PhagsPa} -size 13")
        self.projectname_1.configure(foreground="#000000")
        self.projectname_1.configure(highlightbackground="#d9d9d9")
        self.projectname_1.configure(highlightcolor="black")
        self.projectname_1.configure(insertbackground="black")
        self.projectname_1.configure(selectbackground="blue")
        self.projectname_1.configure(selectforeground="white")

        self.startcrawl = tk.Button(self.setupwindow)
        self.startcrawl.place(relx=0.36, rely=0.775, height=54, width=247
                , bordermode='ignore')
        self.startcrawl.configure(activebackground="#ececec")
        self.startcrawl.configure(activeforeground="#000000")
        self.startcrawl.configure(background="#d9d9d9")
        self.startcrawl.configure(command=self.startcrawling)
        self.startcrawl.configure(cursor="hand2")
        self.startcrawl.configure(disabledforeground="#a3a3a3")
        self.startcrawl.configure(font="-family {Microsoft PhagsPa} -size 14")
        self.startcrawl.configure(foreground="#000000")
        self.startcrawl.configure(highlightbackground="#d9d9d9")
        self.startcrawl.configure(highlightcolor="#000000")
        self.startcrawl.configure(pady="0")
        self.startcrawl.configure(text='''Start Crawling''')

        self.Label1 = tk.Label(self.setupwindow)
        self.Label1.place(relx=0.131, rely=0.636, height=61, width=675
                , bordermode='ignore')
        self.Label1.configure(activebackground="#f9f9f9")
        self.Label1.configure(activeforeground="black")
        self.Label1.configure(background="#d9d9d9")
        self.Label1.configure(disabledforeground="#a3a3a3")
        self.Label1.configure(font="-family {Microsoft PhagsPa} -size 19")
        self.Label1.configure(foreground="#df151b")
        self.Label1.configure(highlightbackground="#d9d9d9")
        self.Label1.configure(highlightcolor="#646464646464")
        self.Label1.configure(text='''** Sorry, This path is invalid.''')
        self.Label1.place_forget()
        self.menubar = tk.Menu(top,font="TkMenuFont",bg=_bgcolor,fg=_fgcolor)
        top.configure(menu = self.menubar)

        self.crawlwindow = tk.LabelFrame(top)
        self.crawlwindow.place(relx=0.011, rely=0.015, relheight=0.998
                , relwidth=1.171)
                 
        self.crawlwindow.configure(relief='groove')
        self.crawlwindow.configure(foreground="black")
        self.crawlwindow.configure(text='''Crawling ...''')
        self.crawlwindow.configure(background="#d9d9d9")
        self.crawlwindow.configure(highlightbackground="#d9d9d9")
        self.crawlwindow.configure(highlightcolor="black")
        
        
        self.f2pinfo=self.crawlwindow.place_info()
        self.crawlwindow.place_forget()
        
        
        
        self.Labelframe2 = tk.LabelFrame(self.crawlwindow)
        self.Labelframe2.place(relx=0.009, rely=0.059, relheight=0.112
                , relwidth=0.825, bordermode='ignore')
        self.Labelframe2.configure(relief='groove')
        self.Labelframe2.configure(foreground="black")
        self.Labelframe2.configure(text='''Status''')
        self.Labelframe2.configure(background="#d9d9d9")
        self.Labelframe2.configure(highlightbackground="#d9d9d9")
        self.Labelframe2.configure(highlightcolor="black")



        self.Label2 = tk.Label(self.Labelframe2)
        self.Label2.place(relx=0.045, rely=0.135, height=59, width=537
                , bordermode='ignore')
        self.Label2.configure(activebackground="#f9f9f9")
        self.Label2.configure(activeforeground="black")
        self.Label2.configure(background="#d9d9d9")
        self.Label2.configure(disabledforeground="#a3a3a3")
        self.Label2.configure(font="-family {Microsoft PhagsPa} -size 22")
        self.Label2.configure(foreground="#000000")
        self.Label2.configure(highlightbackground="#d9d9d9")
        self.Label2.configure(highlightcolor="black")
        self.Label2.configure(justify='right')
        self.Label2.configure(text='''''')

 


        self.developer = tk.Label(self.setupwindow)
        self.developer.place(relx=0.72, rely=0.94, height=35, width=250, bordermode='ignore')
        self.developer.configure(activebackground="#f9f9f9")
        self.developer.configure(activeforeground="black")
        self.developer.configure(background="#d9d9d9")
        self.developer.configure(disabledforeground="#a3a3a3")
        self.developer.configure(font="-family {Microsoft PhagsPa} -size 12")
        self.developer.configure(foreground="Blue")
        self.developer.configure(highlightbackground="#d9d9d9")
        self.developer.configure(highlightcolor="black")
        self.developer.configure(justify='right')
        self.developer.configure(text='''Developed by: Mashood ur Rehman''')

 




        self.startbtn = tk.Button(self.Labelframe2)
        self.startbtn.place(relx=0.668, rely=0.257, height=44, width=127
                , bordermode='ignore')
        self.startbtn.configure(activebackground="#ececec")
        self.startbtn.configure(activeforeground="#000000")
        self.startbtn.configure(background="#006fe8")
        self.startbtn.configure(disabledforeground="#a3a3a3")
        self.startbtn.configure(font="-family {Microsoft PhagsPa} -size 20")
        self.startbtn.configure(foreground="#f4f2f2")
        self.startbtn.configure(highlightbackground="#d9d9d9")
        self.startbtn.configure(highlightcolor="black")
        self.startbtn.configure(pady="0")
        self.startbtn.configure(text='''Start''') 
        self.startbtn.configure(command=self.initialize)
        self.breakop = tk.Button(self.Labelframe2)
        self.breakop.place(relx=0.835, rely=0.257, height=44, width=127
                , bordermode='ignore')
        self.breakop.configure(activebackground="#ececec")
        self.breakop.configure(activeforeground="#000000")
        self.breakop.configure(background="#df092e")
        self.breakop.configure(disabledforeground="#a3a3a3")
        self.breakop.configure(font="-family {Microsoft PhagsPa} -size 20")
        self.breakop.configure(foreground="#f4f2f2")
        self.breakop.configure(highlightbackground="#d9d9d9")
        self.breakop.configure(highlightcolor="black")
        self.breakop.configure(pady="0")
        self.breakop.configure(command=self.GOBACK)
        self.breakop.configure(text='''Go Back''')

        self.log = tk.LabelFrame(self.crawlwindow)
        self.log.place(relx=0.009, rely=0.206, relheight=0.771, relwidth=0.826
                , bordermode='ignore')
        self.log.configure(relief='groove')
        self.log.configure(foreground="black")
        self.log.configure(text='''LOG data''')
        self.log.configure(background="#d9d9d9")
        self.log.configure(highlightbackground="#d9d9d9")
        self.log.configure(highlightcolor="black")

        self.textbox = tk.Text(self.log)
        self.textbox.place(relx=0.011, rely=0.037, relheight=0.941
                , relwidth=0.977, bordermode='ignore')
        self.textbox.configure(background="#cbc9ca")
        self.textbox.configure(font="-family {Microsoft PhagsPa} -size 12")
        self.textbox.configure(foreground="black")
        self.textbox.configure(highlightbackground="#d9d9d9")
        self.textbox.configure(highlightcolor="black")
        self.textbox.configure(insertbackground="black")
        self.textbox.configure(selectbackground="blue")
        self.textbox.configure(selectforeground="#858585")
        self.textbox.configure(wrap="word")
        scrollbar = Scrollbar(self.textbox)
        self.t = tk.Text(self.textbox, height=479, width=878, yscrollcommand=scrollbar.set)
        scrollbar.config(command=self.t.yview)
        scrollbar.pack(side=RIGHT, fill=Y)
        self.t.pack(side="left")
     def startcrawling(self): 
          response = self.VALIDATE()
          print(response)
          if response is True:
             self.OSGETCWD=os.path.join(self.inputfolderlocation,self.inputprojectname) 
             print(self.OSGETCWD)
             self.Label1.place_forget()
             self.f1pinfo=self.setupwindow.place_info()
             self.setupwindow.place_forget()
             self.crawlwindow.place(self.f2pinfo)
             self.CRAWLINGCOMPLETED=False

     def GOBACK(self): 
          self.crawlwindow.place_forget()
          self.setupwindow.place(self.f1pinfo)
          self.startbtn.configure(text="Start")
          self.CRAWLINGCOMPLETED=False
          self.t.configure(text="")


     def openfolder(self):
          folder_selected = filedialog.askdirectory()
          self.folderlocation_1.configure(state='normal')
          self.folderlocation_1.delete(0,'end')
          self.folderlocation_1.insert(0,folder_selected)
          self.folderlocation_1.configure(state='readonly')
          self.inputfolderlocation=folder_selected    

     def VALIDATE(self):  
          self.Label1.pack()
          self.Label1.place(relx=0.131, rely=0.636, height=61, width=675, bordermode='ignore')
          self.inputtargeturl=str(self.targeturl_2.get()).strip().replace('\n','')
          self.inputprojectname=str(self.projectname_1.get()).strip().replace('\n','')
          if not os.path.exists(self.inputfolderlocation) or self.inputprojectname=='':
               
               self.Label1.configure(text='** Sorry, Please use correct path')
               return False
          if urllib.parse.urlsplit(self.inputtargeturl).netloc=='':
               self.Label1.configure(text='** Sorry, Please use correct path')

          if not requests.get(self.inputtargeturl).status_code==200:
               self.Label1.configure(text='** Sorry, Please use correct URL')
               return False
          else:
               if os.path.exists(os.path.join(self.inputfolderlocation,self.inputprojectname)): 
                    self.Label1.configure(text='** Sorry, Folder already exists.')
                    return False
               else:
                    os.makedirs(os.path.join(self.inputfolderlocation,self.inputprojectname))   

               
               return True


    #  ____________________________INITIALIZING CRAWLER

     def initialize(self):
          if self.CRAWLINGCOMPLETED is not True:
               self.Label2.configure(text='''Generating sitemap ...''')
               self.t.insert(tk.END, f'Generating Sitemap .............. \n')
               self.textbox.see(tk.END)         
               self.startbtn["state"] = "disabled"
               self.breakop["state"] = "disabled"  
               self.startbtn.after(2000,self.sitemaper)  
          elif self.CRAWLINGCOMPLETED is True:
               os.system(f'start {self.inputfolderlocation}')
  
    #  ____________________________GENERATE SITEMAPP
     def sitemaper(self):
        from pysitemap import crawler
        self.root_url = self.inputtargeturl+'/' if not self.inputtargeturl.endswith('/') else self.inputtargeturl
     #    self.root_url = 'https://unityfreepaidassets.com/'
        crawler(self.root_url, out_file=os.path.join(self.OSGETCWD,'sitemap.txt' ),out_format='txt')
        with open(os.path.join(self.OSGETCWD,'sitemap.txt' ), 'rb') as target:
            self.all_lines=[x.decode('utf-8') for x in target.readlines()]
        self.read_ref( self.all_lines,'''Downloading HTML files...''')  
          
        
     def simpleprinetr(self,data):
            self.t.insert("end", data )  
            self.t.see(tk.END) 
     def read_ref(self, lines,text): 
        line = lines.pop(0)  
        self.t.insert("end", line )  
        self.t.see(tk.END) 
        if lines:
               self.Label2.after(10, self.read_ref, lines,text)   
        else:
                
               self.Label2.configure(text=text)
                
               if text=='Downloading HTML files...':
                    rawfiles=[]
                    with open(os.path.join(self.OSGETCWD, 'sitemap.txt'),'r') as target: 
                              for x in [x.strip() for x in target.readlines() if not '.css' in x.strip() and not '.js' in x.strip() and not x.strip().endswith(tuple(['png', 'jpg', 'jpeg','wepb'])) ]:
                                   url=x[0:-1] if x.strip().endswith('/') else x.strip()
                                   if url==self.root_url[0:-1]:filename='default_home.html'
                                   else:filename=url.split('/')[-1]
                                   if filename.endswith('.html'):filename=filename
                                   else:filename=filename+'.html'
                                   if filename.endswith('.asp'):filename=filename.replace('.asp','.html')  
                                   rawfiles.append([x.strip(),filename])
                    self.Label2.after(200,self.starthtmldownloader,rawfiles)
       
               if text=='Analyzing Static Files ...':
                    self.STARTSTATICFILEANALYZER()
               if text=='Downloading Static files ...':
                    self.Label2.configure(text=text)
                    self.DOWNLOADSTATICFILES()     
               if text=='Analyzing internal HREFS  ...':
                    self.Label2.configure(text=text)
                    self.ANALYZEINTERNALHREFS()     
               if text=="Making files Ready for you ...":
                    self.UPDATEHTMLFILES()
               if text=='FINISHED':
                    self.Label2.configure(text="Crawling Successful 😉")
                    self.Label2.configure(foreground="green")
                    self.startbtn.configure(command=None)
                    self.startbtn["state"] = "normal"
                    self.breakop["state"] = "normal"  
                    self.startbtn.configure(font="-family {Microsoft PhagsPa} -size 15")
                    self.startbtn.configure(text="Open Project")
                    self.CRAWLINGCOMPLETED=True
                    # self.inputfolderlocation=''
                    # self.inputprojectname=''
                    # self.inputtargeturl=''








     def starthtmldownloader(self,rawfiles):
        self.htmldownloadedMETAdata=[] 
        def html_fetcher(alllinks):
                if os.path.exists(os.path.join(self.OSGETCWD,'HTML')): pass
                else:os.makedirs(os.path.join(self.OSGETCWD,'HTML'))
                with requests.Session() as session:
                        for url in alllinks:  
                                # 
                                print(url[-1])
                                self.htmldownloadedMETAdata.append(url[-1]+'\n')
                                results=session.get(url[0])  
                                print(results.status_code)
                                self.htmldownloadedMETAdata.append(str(results.status_code)+'\n')
                                try:
                                        if results.status_code==200: 
                                                with open(os.path.join(self.OSGETCWD,'HTML',url[-1]) ,'wb') as file:
                                                        file.write(results.text.encode('utf-8')) 
                                                        self.htmldownloadedMETAdata.append('____________________HTML______100'+'\n') 
                                                        print('____________________HTML______100')
                                except:
                                        self.htmldownloadedMETAdata.append('____________________EXCEPTION___HANDLING'+'\n')
                                        print('____________________EXCEPTION___HANDLING'+'\n')
                
        self.Label2.configure(text='''Analyzing Static Files ...''')
        
                        
        html_fetcher(rawfiles)
        self.read_ref( self.htmldownloadedMETAdata,"Analyzing Static Files ...")   
   
     def STARTSTATICFILEANALYZER(self):
        self.staticfileanalyzedMETAdata=[] 
        rawhtmlfile=[os.path.join(self.OSGETCWD,'HTML',x) for x in os.listdir(os.path.join(self.OSGETCWD,'HTML'))]
        def fetcher(alllinks):   
            jslinks=[]
            csslinks=[]
            imglinks=[]
            index=1
            for url in alllinks:
                with open(url, 'rb') as htmlfile:  
                    soup = bs4(htmlfile,'lxml')  
                    rawcsslinks=soup.find_all('link')
                    for x in rawcsslinks:
                        if '.css' in x['href']:csslinks.append(x['href'])
                
                    rawjslinks=soup.find_all('script')
                    for x in rawjslinks:
                        try:
                            if '.js' in x['src']:jslinks.append(x['src'])
                        except:pass
                
                    rawimglinks=soup.find_all('img')
                    for x in rawimglinks:
                        imglinks.append(x['src'])
                print(f'{index} files have been fileterd !!!')
                self.staticfileanalyzedMETAdata.append(f'{index} files have been fileterd !!!\n')
                index=index+1

            return [list(set(csslinks)),list(set(jslinks)),list(set(imglinks))]

        

        
        def generatestaticlinks():
            data=fetcher(rawhtmlfile)  
            with open(os.path.join(self.OSGETCWD,'static_links.json' ), 'w') as outfile:
                json.dump({"all_links":data}  , outfile)
                self.staticfileanalyzedMETAdata.append('_____________________________STATIC_FILES_REGISTERED__100%\n')
                print('_____________________________STATIC_FILES_REGISTERED__100%\n')
  
        generatestaticlinks()
        self.read_ref( self.staticfileanalyzedMETAdata,"Downloading Static files ...")  




     # DOWNLOAD STATIC FILES
     def DOWNLOADSTATICFILES(self):  
          self.DOWNLOADSTATICFILESMETADATA=[]
          self.root_url=self.root_url+'/' if not self.root_url.endswith('/') else self.root_url
          PARSED_ROOT_URL=urllib.parse.urlsplit(self.root_url)
          ENCODED_STATIC_FILES_DATA=[]
          def get_static_links():
                    with open(os.path.join(self.OSGETCWD,'static_links.json' )) as json_file:
                         static_links = json.load(json_file)['all_links']
                         return static_links
          STATIC_FILES=get_static_links() 
          self.ACCURATE_CSS_ROOT_URL=''

          def createcssfiles(url,session):
                    url=url[0:-1] if url.endswith('/') else url
                    filename=url.split('/')[-1] 
                    fileextension=filename.split('.')[-1]
                    if '?' in filename:
                         if '.css' in filename:fileextension='.css'
                         elif '.js' in filename:fileextension='.js'
                         elif '.png' in filename:fileextension='.php'
                         elif '.jpg' in filename:fileextension='.jpg'
                         elif '.jpeg' in filename:fileextension='.jpeg'
                         elif '.ico' in filename:fileextension='.ico'
                         elif '.gif' in filename:fileextension='.gif'
                         elif '.webp' in filename:fileextension='.webp'
                         filename=str(uuid.uuid4()).replace('-','')+'.'+fileextension
                         # self.DOWNLOADSTATICFILESMETADATA.append(str('+++++++++++++++'+filename)+'\n')
                         print('+++++++++++++++',filename)


                    if not os.path.exists(os.path.join(self.OSGETCWD,'Static',filename)):
                         if 'js' in fileextension or 'css' in fileextension:
                              with open(os.path.join(self.OSGETCWD,'Static',filename),'wb') as target:
                                   target.write(session.get(self.ACCURATE_CSS_ROOT_URL+url).text.encode('utf-8'))
                                   self.DOWNLOADSTATICFILESMETADATA.append(f'________{filename}.{fileextension}___WRITTEN\n')
                                   print(f'{filename}________{filename}.{fileextension}___WRITTEN')    
                         else:
                              with open(os.path.join(self.OSGETCWD,'Static',filename),'wb') as target:
                                   target.write(session.get(self.ACCURATE_CSS_ROOT_URL+url).content)
                                   self.DOWNLOADSTATICFILESMETADATA.append(f'________{fileextension}___WRITTEN\n')
                                   print(f'{filename}________{filename}.{fileextension}___WRITTEN')    
                    else:
                         self.DOWNLOADSTATICFILESMETADATA.append(f'________{fileextension}____________ALREADY___EXISTS !!!\n')
                         print(f'{filename}________.{fileextension}____________ALREADY___EXISTS !!!')
                    data={
                         'orignalurl':url,
                         'newurl':f'../Static/{filename}',
                         'encodedurl':True if '?' in filename else False
                    } 
                    ENCODED_STATIC_FILES_DATA.append(data)
          def getcssfiles(cssfiles):  
               # global self.ACCURATE_CSS_ROOT_URL
               if os.path.exists(os.path.join(self.OSGETCWD,'Static')):pass
               else:os.makedirs(os.path.join(self.OSGETCWD,'Static'))
               with requests.Session() as session:
                    for x in cssfiles:
                         if not x.startswith('http'):
                              # main function to handle 100% ACCURATE url of STATIC FILES
                              
                              # accurate root is alreay avaliable
                              if self.ACCURATE_CSS_ROOT_URL!='':
                                   createcssfiles(x, session)
                              else:
                                   acuuratestaticurl=''
                                   if PARSED_ROOT_URL.path=='/': 
                                        acuuratestaticurl=self.root_url
                                        self.ACCURATE_CSS_ROOT_URL=acuuratestaticurl
                                        createcssfiles(x, session)
                                   elif PARSED_ROOT_URL.path!='/':
                                        acuuratestaticurl=self.root_url
                                        if requests.get(acuuratestaticurl+x).status_code==200:
                                                  # write file
                                                  self.ACCURATE_CSS_ROOT_URL=acuuratestaticurl
                                                  createcssfiles(x, session)
                                                  continue
                                        # if DOT is in last string 
                                        if '.'  in self.root_url[0:-1].split('/')[-1]:
                                             acuuratestaticurl=self.root_url[0:-1].replace(self.root_url[0:-1].split('/')[-1],'')+x
                                             test1url=self.root_url[0:-1].replace(self.root_url[0:-1].split('/')[-1],'')
                                             if requests.get(acuuratestaticurl).status_code==200:
                                                  # write file
                                                  self.ACCURATE_CSS_ROOT_URL=test1url
                                                  createcssfiles(x, session)
                                                  
                                             elif requests.get(acuuratestaticurl).status_code!=200:
                                                  test2url=test1url[0:-1].replace(test1url[0:-1].split('/')[-1],'')
                                                  acuuratestaticurl=test2url+x
                                                  if requests.get(acuuratestaticurl).status_code==200:
                                                       # write file
                                                       self.ACCURATE_CSS_ROOT_URL=test2url
                                                       createcssfiles(x, session)
                                                       pass
                                                  else:
                                                       test3url=test2url[0:-1].replace(test2url[0:-1].split('/')[-1],'')
                                                       acuuratestaticurl=test3url+x
                                                       self.ACCURATE_CSS_ROOT_URL=test3url
                                                       createcssfiles(x, session)
                                        # IF DOT isn't in the last string
                                        else:         
                                             acuuratestaticurl=self.root_url[0:-1].replace(self.root_url[0:-1].split('/')[-1],'')+x
                                             test1url=self.root_url[0:-1].replace(self.root_url[0:-1].split('/')[-1],'')
                                             if requests.get(acuuratestaticurl).status_code==200:
                                                  # write file
                                                  self.ACCURATE_CSS_ROOT_URL=test1url
                                                  createcssfiles(x, session)
                                             elif requests.get(acuuratestaticurl).status_code!=200:
                                                  test2url=test1url[0:-1].replace(test1url[0:-1].split('/')[-1],'')
                                                  acuuratestaticurl=test2url+x
                                                  if requests.get(acuuratestaticurl).status_code==200:
                                                       # write file
                                                       self.ACCURATE_CSS_ROOT_URL=test2url
                                                       createcssfiles(x, session)
                                                       pass
                                                  else:
                                                       test3url=test2url[0:-1].replace(test2url[0:-1].split('/')[-1],'')
                                                       acuuratestaticurl=test3url+x
                                                       self.ACCURATE_CSS_ROOT_URL=test3url
                                                       createcssfiles(x, session)
                                    
						
          def downloadSTATICfiles():      
               getcssfiles(STATIC_FILES[0])
               getcssfiles(STATIC_FILES[1])
               getcssfiles(STATIC_FILES[2]) 
               with open(os.path.join(self.OSGETCWD,'encoded_static_files_data.json' ), 'w') as outfile:
                    json.dump({"allstaticdata":ENCODED_STATIC_FILES_DATA}  , outfile)

          downloadSTATICfiles()
          self.read_ref( self.DOWNLOADSTATICFILESMETADATA,"Analyzing internal HREFS  ...")  

   

   
     def ANALYZEINTERNALHREFS(self): 
          self.INTERNALHREFSMETADATA=[]
          from iteration_utilities import unique_everseen 
          rawhtmlfile=[x for x in os.listdir(os.path.join(self.OSGETCWD,'HTML'))]
          rawfiles=[x.replace('.html','') for x in os.listdir(os.path.join(self.OSGETCWD,'HTML'))]
          FILTERED_HREFS=[]

          def fetcher(alllinks):  
               def fetch(url):    
                    with open(os.path.join(self.OSGETCWD,'HTML',url), 'rb') as target:
                         data=" ".join([x.decode('utf8') for x in target.readlines()]) 
                         soup=bs4(data,'lxml')
                         allhrefs=[x for x in soup.find_all('a')]
                         pureallhrefs=[]
                         for x in allhrefs:
                              try:
                                   if not x['href'].startswith('#') and not x['href'].startswith('http'):
                                        pureallhrefs.append(x)
                              except :pass 
                         for x in pureallhrefs:
                              targethref=''
                              if '.html' in x['href']:
                                   targethref=[y for y in rawhtmlfile if y in x['href'][0]] 
                              elif x['href']=='/':
                                   targethref='default_home.html'
                              for z in rawfiles:
                                   if x['href'].endswith(z):
                                        targethref=z+'.html' 
                              for z in rawfiles:
                                   if z in x['href']:
                                        targethref=z+'.html'
                              else:
                                   targethref=x['href']
                              self.INTERNALHREFSMETADATA.append(str({'old':x['href'],'new':targethref})+'\n')
                              print({'old':x['href'],'new':targethref})
                              
                              targethref=targethref[0:-1] if targethref.endswith('/') else targethref
                              targethref=targethref.split('/')[-1]
                              targethref=targethref+'.html' if not targethref.endswith('.html') else targethref
                              FILTERED_HREFS.append({'old':x['href'],'new':targethref})
                    self.INTERNALHREFSMETADATA.append(f'LINK___{url}____FILTERED \n')
                    print(f'LINK___{url}____FILTERED ')
                              
                         
                    
                    
               def starter():
                    with ThreadPoolExecutor(max_workers=100) as executor: 
                         executor.map(fetch,  [x for x in alllinks])
                         executor.shutdown(wait=True)
               starter()  

                    
                    
                    
          FILTERED_HREFS=list(unique_everseen(FILTERED_HREFS)) 



          def handleinternalhref():
               fetcher(rawhtmlfile) 
               with open(os.path.join(self.OSGETCWD,'filtered_hrefs.json' ), 'w') as outfile:
                    json.dump({"all_links":FILTERED_HREFS}  , outfile)
                    self.INTERNALHREFSMETADATA.append('_____________________________FILTERED_HREFS__100%\n')
                    self.INTERNALHREFSMETADATA.append('_____________________________FILTERED_HREFS__100%\n')
                    self.INTERNALHREFSMETADATA.append("="*120+'\n')
                    
                    print('_____________________________FILTERED_HREFS__100%')

          handleinternalhref()
          self.read_ref( self.INTERNALHREFSMETADATA,"Making files Ready for you ...") 
   

     def UPDATEHTMLFILES(self):
          self.UPDATINGHTMLMETADATA=[]
          print('+'*200)
          from iteration_utilities import unique_everseen 
          rawhtmlfile=[x for x in os.listdir(os.path.join(self.OSGETCWD,'HTML'))]
          rawfiles=[x.replace('.html','') for x in os.listdir(os.path.join(self.OSGETCWD,'HTML'))]
          def getfilteredhrefs():
               with open(os.path.join(self.OSGETCWD, 'filtered_hrefs.json'),'rb') as json_file:
                    data = json.load(json_file)['all_links']
                    return data

          def getencodestaticfilesdata():
               with open(os.path.join(self.OSGETCWD,'encoded_static_files_data.json' ),'rb') as json_file:
                    data = json.load(json_file)['allstaticdata']
                    return data

 
          def readHTML(filename):
               with open(os.path.join(self.OSGETCWD,'HTML',filename), 'rb') as target:
                    data=" ".join([x.decode('utf8') for x in target.readlines()])
                    return bs4(data,'lxml')
          def writeHTML(filename,data):
               with open(os.path.join(self.OSGETCWD,'HTML',filename), 'wb') as target: 
                    target.write(str(data).encode('utf-8'))

          def fetcher(alllinks):   
               self.repeat=0
               try:
                    for url in alllinks: 
                         soup=readHTML(url)
                         csslinks=soup.find_all('link')      
                         for x in csslinks:
                              for y in getencodestaticfilesdata():
                                   if x['href']==y['orignalurl']:
                                        x['href']=y['newurl']  
                         imglinks=soup.find_all('img')      
                         for x in imglinks:
                              for y in getencodestaticfilesdata():
                                   if x['src']==y['orignalurl'] or  x['src'].startswith(y['orignalurl']) or x['src'].endswith(y['orignalurl']):
                                        x['src']=y['newurl']  
                         jslinks=soup.find_all('script')      
                         for x in jslinks:
                              for y in getencodestaticfilesdata():
                                   try:
                                        if x['src']==y['orignalurl'] or  x['src'].startswith(y['orignalurl']) or x['src'].endswith(y['orignalurl']):
                                             x['src']=y['newurl'] 
                                   except:pass
                         hrefs=soup.find_all('a')      
                         for x in hrefs:
                              for y in getfilteredhrefs():
                                   try:
                                        if x['href']==y['old']:  
                                             x['href']=y['new'] 
                                        
                                   except:pass      
                         writeHTML(url,soup)   
                         self.UPDATINGHTMLMETADATA.append(url+'_______HAS BEEN UPDATED\n')
                         print(url+'HAS BEEN UPDATED')        
               except Exception as e:
                    print('error')
                    if self.repeat==0:
                         fetcher(rawhtmlfile)       
                    else:
                         self.UPDATINGHTMLMETADATA.append(str(str(e)[:400])+'\n')
                         print(str(e)[:400])
          fetcher(rawhtmlfile) 
          

          

               
                                                                                                                                                                                                                                                                                                         
                                                             




          
          self.UPDATINGHTMLMETADATA.append(str('\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //===========================================================//\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //                                                           //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //  #####  ##  ##     ##  ##   ####  ##   ##  #####  ####    //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //  ##     ##  ####   ##  ##  ##     ##   ##  ##     ##  ##  //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //  #####  ##  ##  ## ##  ##   ###   #######  #####  ##  ##  //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //  ##     ##  ##    ###  ##     ##  ##   ##  ##     ##  ##  //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //  ##     ##  ##     ##  ##  ####   ##   ##  #####  ####    //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //                                                           //\n'))
          self.UPDATINGHTMLMETADATA.append(str('                      //===========================================================//\n'))
          self.UPDATINGHTMLMETADATA.append(str('\n'))
          



          self.read_ref( self.UPDATINGHTMLMETADATA,"FINISHED") 







   
   
    
   
   
if __name__ == '__main__':
    vp_start_gui()



 
